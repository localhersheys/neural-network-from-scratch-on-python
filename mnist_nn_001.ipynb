{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 34877,
          "sourceType": "datasetVersion",
          "datasetId": 27352
        }
      ],
      "dockerImageVersionId": 30715,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "mnist_nn_001",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/localhersheys/neural-network-from-scratch-on-python/blob/main/mnist_nn_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'mnist-in-csv:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F27352%2F34877%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240602%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240602T101045Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D66d0e51cd43ffa362404acc436da188c407a78cbd79463e0b05da0f202adae70f29eb926db856bd13241e1de8ac05ba5c7caec50f32bf4b2588ac09cb411edb09566a51ed0583caf0888bae9a9cb7bbb115557adca742eab39497e773cb8f71d826d3e88d177f6c5bab35ac4ac3ad737bed8d7bbc9e39c0886317146326168afd456b16a4d0e3815c169b248dd32d281f30d8d81007038b3a826d47e1678cb7bc72416d3a110e1ccbf4519f657cc83abd2521f643fcd5fbb29d4e8f179438663cb7ac1b215ae98a8dde5bba4ec4aa253b0c7e81d12edd8d8b49bb717c4240ce8eaa6abae90d63b274b26a8a4e9b01bb34e4248bae3bb1d3979ec57d6bf286166'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "zP2lygpWcOxe"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #for dealing with matrices\n",
        "import pandas as pd #for importing the data\n",
        "\n",
        "#importing testing and training data\n",
        "data_train = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\n",
        "data_test = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_test.csv')\n",
        "\n",
        "data_train"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-02T09:16:39.622273Z",
          "iopub.execute_input": "2024-06-02T09:16:39.622652Z",
          "iopub.status.idle": "2024-06-02T09:16:44.907152Z",
          "shell.execute_reply.started": "2024-06-02T09:16:39.622625Z",
          "shell.execute_reply": "2024-06-02T09:16:44.906098Z"
        },
        "trusted": true,
        "id": "2Y4wikSUcOxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting pandas table to numpy array\n",
        "data_train = np.array( data_train ).T\n",
        "data_test = np.array( data_test ).T\n",
        "\n",
        "data_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T09:16:44.909044Z",
          "iopub.execute_input": "2024-06-02T09:16:44.909388Z",
          "iopub.status.idle": "2024-06-02T09:16:45.140137Z",
          "shell.execute_reply.started": "2024-06-02T09:16:44.909359Z",
          "shell.execute_reply": "2024-06-02T09:16:45.139118Z"
        },
        "trusted": true,
        "id": "WLj7S9IwcOxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividing data into labels and pixels\n",
        "Y_train = data_train[0]\n",
        "X_train = data_train[1:]\n",
        "\n",
        "Y_test = data_test[0]\n",
        "X_test = data_test[1:]\n",
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T09:16:51.330751Z",
          "iopub.execute_input": "2024-06-02T09:16:51.331519Z",
          "iopub.status.idle": "2024-06-02T09:16:51.341953Z",
          "shell.execute_reply.started": "2024-06-02T09:16:51.331484Z",
          "shell.execute_reply": "2024-06-02T09:16:51.340764Z"
        },
        "trusted": true,
        "id": "jN_6LjmdcOxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing the data\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T09:16:55.385242Z",
          "iopub.execute_input": "2024-06-02T09:16:55.385603Z",
          "iopub.status.idle": "2024-06-02T09:16:55.562213Z",
          "shell.execute_reply.started": "2024-06-02T09:16:55.385576Z",
          "shell.execute_reply": "2024-06-02T09:16:55.561214Z"
        },
        "trusted": true,
        "id": "W-b6KSJ0cOxl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape = no. of rows , no. of columns\n",
        "n, m = X_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T09:17:00.24486Z",
          "iopub.execute_input": "2024-06-02T09:17:00.245244Z",
          "iopub.status.idle": "2024-06-02T09:17:00.253263Z",
          "shell.execute_reply.started": "2024-06-02T09:17:00.245215Z",
          "shell.execute_reply": "2024-06-02T09:17:00.252025Z"
        },
        "trusted": true,
        "id": "KrTn9TJtcOxm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize parameters\n",
        "def init_params():\n",
        "    W1 = np.random.rand(10 , 784) - 0.5\n",
        "    b1 = np.random.rand(10 , 1) - 0.5\n",
        "    W2 = np.random.rand(10 , 10) - 0.5\n",
        "    b2 = np.random.rand(10 , 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "#defining activation functions ReLU and softmax\n",
        "def ReLU(X):\n",
        "    return np.maximum(0 , X)\n",
        "\n",
        "def softmax(X):\n",
        "    return np.exp(X)/ sum(np.exp(X))\n",
        "\n",
        "#calculating value of each layer given the weights and biases\n",
        "def fwd_prop(X, W1, b1, W2, b2):\n",
        "    A1 = W1.dot(X) + b1\n",
        "    Z1 = ReLU(A1)\n",
        "    A2 = W2.dot(Z1) + b2\n",
        "    Z2 = softmax(A2)\n",
        "    return A1, Z1, A2, Z2\n",
        "\n",
        "#defining a function for one hot encoding of Y\n",
        "def one_hot_encode(Y, Z2):\n",
        "    one_hot_Y = np.zeros(Z2.shape).T\n",
        "    one_hot_Y[np.arange(Y.size),Y] = 1\n",
        "    return one_hot_Y.T\n",
        "\n",
        "#defining function for derivative of ReLU\n",
        "def deriv(X):\n",
        "    return X>0\n",
        "\n",
        "#finding the amount of change we need to introduce to the weights and biases\n",
        "def bwd_prop(X, Y, Z2, Z1, A1, W2):\n",
        "    m = Y.size\n",
        "    dZ2 = Z2 - one_hot_encode(Y,Z2)\n",
        "    dW2 = 1/m * dZ2.dot(Z1.T)\n",
        "    db2 = 1/m * np.sum(dZ2)\n",
        "    dZ1 = W2.T.dot(dZ2)*deriv(A1)\n",
        "    dW1 = 1/m *dZ1.dot(X.T)\n",
        "    db1 = 1/m * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "#updating the weights and biases\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T09:17:02.674573Z",
          "iopub.execute_input": "2024-06-02T09:17:02.674977Z",
          "iopub.status.idle": "2024-06-02T09:17:02.690507Z",
          "shell.execute_reply.started": "2024-06-02T09:17:02.674947Z",
          "shell.execute_reply": "2024-06-02T09:17:02.689113Z"
        },
        "trusted": true,
        "id": "gGsZ9ivccOxm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the predictions given the final layer\n",
        "def get_predictions(Z2):\n",
        "    return np.argmax(Z2, 0)\n",
        "\n",
        "#get accuracy given the prediction and label\n",
        "def get_accuracy(prediction , Y):\n",
        "    return sum( prediction == Y ) / Y.size"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T08:56:55.144641Z",
          "iopub.execute_input": "2024-06-02T08:56:55.145458Z",
          "iopub.status.idle": "2024-06-02T08:56:55.151002Z",
          "shell.execute_reply.started": "2024-06-02T08:56:55.145423Z",
          "shell.execute_reply": "2024-06-02T08:56:55.149872Z"
        },
        "trusted": true,
        "id": "0eQsO-2scOxm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for running the model given X, Y, learning rate (alpha) and iteration\n",
        "def train(X, Y, alpha, iterations):\n",
        "    #initializing weights and biases\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations+1):\n",
        "        #finding values of each layer\n",
        "        A1, Z1, A2, Z2 = fwd_prop(X, W1, b1, W2, b2)\n",
        "        #finding the amount of change we need to introduce to the weights and biases\n",
        "        dW1, db1, dW2, db2 = bwd_prop(X, Y, Z2, Z1, A1, W2)\n",
        "        #updating the parameters according to the values found above\n",
        "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
        "\n",
        "        #print the accuracy if iteration number is a multiple of 100\n",
        "        if i%100 == 0 :\n",
        "            print(\"iteration :\" , i)\n",
        "            print(\"accuracy : \" , get_accuracy(get_predictions(Z2) , Y))\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T08:56:57.834687Z",
          "iopub.execute_input": "2024-06-02T08:56:57.835782Z",
          "iopub.status.idle": "2024-06-02T08:56:57.844163Z",
          "shell.execute_reply.started": "2024-06-02T08:56:57.835745Z",
          "shell.execute_reply": "2024-06-02T08:56:57.842899Z"
        },
        "trusted": true,
        "id": "elhLO4s2cOxn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1, W2, b2 = train(X_train , Y_train , 0.1 , 500 )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T08:57:01.850159Z",
          "iopub.execute_input": "2024-06-02T08:57:01.850561Z",
          "iopub.status.idle": "2024-06-02T08:58:30.866717Z",
          "shell.execute_reply.started": "2024-06-02T08:57:01.85053Z",
          "shell.execute_reply": "2024-06-02T08:58:30.865617Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysSeexmocOxn",
        "outputId": "079e69c0-7b48-49b9-9501-4047491faa4f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration : 0\n",
            "accuracy :  0.09378333333333333\n",
            "iteration : 100\n",
            "accuracy :  0.68545\n",
            "iteration : 200\n",
            "accuracy :  0.7862833333333333\n",
            "iteration : 300\n",
            "accuracy :  0.8240333333333333\n",
            "iteration : 400\n",
            "accuracy :  0.84415\n",
            "iteration : 500\n",
            "accuracy :  0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A1_test, Z1_test, A2_test, Z2_test = fwd_prop(X_test, W1, b1, W2, b2)\n",
        "test_predictions = get_predictions(Z2_test)\n",
        "get_accuracy(test_predictions, Y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-02T10:10:38.136645Z",
          "iopub.execute_input": "2024-06-02T10:10:38.137149Z",
          "iopub.status.idle": "2024-06-02T10:10:38.24731Z",
          "shell.execute_reply.started": "2024-06-02T10:10:38.137093Z",
          "shell.execute_reply": "2024-06-02T10:10:38.245571Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_uYE8tdcOxo",
        "outputId": "7e074c82-30fe-4723-9123-1a38970513e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8593"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}